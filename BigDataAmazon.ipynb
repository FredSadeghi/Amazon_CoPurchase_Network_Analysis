{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FredSadeghi/Amazon_CoPurchase_Network_Analysis/blob/main/BigDataAmazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K1oj8EP5ZgpE"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import csv\n",
        "import re\n",
        "import pandas as pd\n",
        "from textblob import TextBlob  # For potential NLP if review text is available\n",
        "import os # Import the os module"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/Amazon_CoPurchase_Network_Analysis'):\n",
        "    !git clone https://github.com/FredSadeghi/Amazon_CoPurchase_Network_Analysis.git\n",
        "else:\n",
        "    print(\"Repository already cloned. Skipping.\")"
      ],
      "metadata": {
        "id": "ZNa-1qgy9J5m",
        "outputId": "e1355516-c981-41cb-8302-048829559cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repository already cloned. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file\n",
        "input_file = '/content/Amazon_CoPurchase_Network_Analysis/amazon-meta.txt.gz'\n",
        "\n",
        "# Output files\n",
        "product_output = 'products_cleaned.csv'\n",
        "category_output = 'categories_cleaned.csv'\n",
        "review_output = 'reviews_cleaned.csv'\n",
        "edge_output = 'edges.csv'  # New output for similar products"
      ],
      "metadata": {
        "id": "s1GXTDjVZxOw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_amazon_data():\n",
        "    \"\"\"Parse raw Amazon metadata into separate CSV files for products, categories, reviews, and edges.\"\"\"\n",
        "    with gzip.open(input_file, 'rt', encoding='latin-1') as f, \\\n",
        "         open(product_output, 'w', newline='', encoding='utf-8') as prod_out, \\\n",
        "         open(category_output, 'w', newline='', encoding='utf-8') as cat_out, \\\n",
        "         open(review_output, 'w', newline='', encoding='utf-8') as rev_out, \\\n",
        "         open(edge_output, 'w', newline='', encoding='utf-8') as edge_out:\n",
        "\n",
        "        product_writer = csv.writer(prod_out)\n",
        "        category_writer = csv.writer(cat_out)\n",
        "        review_writer = csv.writer(rev_out)\n",
        "        edge_writer = csv.writer(edge_out)\n",
        "\n",
        "        # Write headers\n",
        "        product_writer.writerow(['Id', 'ASIN', 'Title', 'Group', 'SalesRank'])\n",
        "        category_writer.writerow(['ASIN', 'CategoryPath'])\n",
        "        review_writer.writerow(['ASIN', 'CustomerID', 'Rating', 'Votes', 'Helpful', 'Sentiment'])\n",
        "        edge_writer.writerow(['SourceASIN', 'TargetASIN'])\n",
        "\n",
        "        current = {}\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # New product entry\n",
        "            if line.startswith(\"Id:\"):\n",
        "                # Save previous product if it exists\n",
        "                if current.get('ASIN') and current.get('Id'):\n",
        "                    product_writer.writerow([\n",
        "                        current.get('Id'),\n",
        "                        current.get('ASIN'),\n",
        "                        current.get('title', 'Unknown'),  # Handle missing title\n",
        "                        current.get('group', 'Unknown'),  # Handle missing group\n",
        "                        current.get('salesrank', '-1')    # Handle missing salesrank\n",
        "                    ])\n",
        "                    for cat in current.get('categories', []):\n",
        "                        category_writer.writerow([current['ASIN'], cat])\n",
        "                    for review in current.get('reviews', []):\n",
        "                        sentiment = compute_sentiment(review['rating'])\n",
        "                        review_writer.writerow([\n",
        "                            current['ASIN'], review['customer'], review['rating'],\n",
        "                            review['votes'], review['helpful'], sentiment\n",
        "                        ])\n",
        "                    for similar_asin in current.get('similar', []):\n",
        "                        edge_writer.writerow([current['ASIN'], similar_asin])\n",
        "                current = {'categories': [], 'reviews': [], 'similar': []}\n",
        "                current['Id'] = line.split('Id:')[1].strip()\n",
        "\n",
        "            elif line.startswith(\"ASIN:\"):\n",
        "                current['ASIN'] = line.split(\"ASIN:\")[1].strip()\n",
        "\n",
        "            elif 'title:' in line:\n",
        "                match = re.search(r'title:\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current['title'] = match.group(1).strip()\n",
        "\n",
        "            elif 'group:' in line:\n",
        "                match = re.search(r'group:\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current['group'] = match.group(1).strip()\n",
        "\n",
        "            elif 'salesrank:' in line:\n",
        "                match = re.search(r'salesrank:\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current['salesrank'] = match.group(1).strip()\n",
        "\n",
        "            elif line.startswith(\"similar:\"):\n",
        "                parts = line.split()\n",
        "                current['similar'] = parts[2:] if len(parts) > 2 else []\n",
        "\n",
        "            elif line.startswith(\"|\"):\n",
        "                current['categories'].append(line.strip())\n",
        "\n",
        "            elif re.match(r'\\d{4}-\\d{1,2}-\\d{1,2}', line):  # Match review date\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 7:\n",
        "                    review = {\n",
        "                        'customer': parts[2],\n",
        "                        'rating': int(parts[4]),\n",
        "                        'votes': int(parts[6]),\n",
        "                        'helpful': int(parts[8])\n",
        "                    }\n",
        "                    current['reviews'].append(review)\n",
        "\n",
        "        # Write the last product\n",
        "        if current.get('ASIN') and current.get('Id'):\n",
        "            product_writer.writerow([\n",
        "                current.get('Id'),\n",
        "                current.get('ASIN'),\n",
        "                current.get('title', 'Unknown'),\n",
        "                current.get('group', 'Unknown'),\n",
        "                current.get('salesrank', '-1')\n",
        "            ])\n",
        "            for cat in current.get('categories', []):\n",
        "                category_writer.writerow([current['ASIN'], cat])\n",
        "            for review in current.get('reviews', []):\n",
        "                sentiment = compute_sentiment(review['rating'])\n",
        "                review_writer.writerow([\n",
        "                    current['ASIN'], review['customer'], review['rating'],\n",
        "                    review['votes'], review['helpful'], sentiment  # Fixed: use review['votes']\n",
        "                ])\n",
        "            for similar_asin in current.get('similar', []):\n",
        "                edge_writer.writerow([current['ASIN'], similar_asin])"
      ],
      "metadata": {
        "id": "4Y5iTTMiZ8-q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sentiment(rating):\n",
        "    \"\"\"Compute a placeholder sentiment score based on rating (no review text available).\"\"\"\n",
        "    if rating <= 2:\n",
        "        return -1.0  # Negative\n",
        "    elif rating == 3:\n",
        "        return 0.0   # Neutral\n",
        "    else:\n",
        "        return 1.0   # Positive"
      ],
      "metadata": {
        "id": "NM22QwiGaC2-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data():\n",
        "    \"\"\"Convert CSV files into cleaned, structured pandas DataFrames.\"\"\"\n",
        "    # Load CSVs\n",
        "    products_df = pd.read_csv(product_output)\n",
        "    categories_df = pd.read_csv(category_output)\n",
        "    reviews_df = pd.read_csv(review_output)\n",
        "\n",
        "    # Clean products DataFrame\n",
        "    products_df['SalesRank'] = pd.to_numeric(products_df['SalesRank'], errors='coerce').fillna(-1).astype(int)\n",
        "    products_df['Title'] = products_df['Title'].fillna('Unknown')\n",
        "    products_df['Group'] = products_df['Group'].fillna('Unknown')\n",
        "\n",
        "    # Parse categories\n",
        "    def parse_category_path(cat_path):\n",
        "        if pd.isna(cat_path):\n",
        "            return []\n",
        "        parts = cat_path.split(\"|\")\n",
        "        return [re.sub(r\"\\[\\d+\\]\", \"\", part).strip() for part in parts if part]\n",
        "\n",
        "    categories_df['CategoryLevels'] = categories_df['CategoryPath'].apply(parse_category_path)\n",
        "    categories_expanded = categories_df.explode('CategoryLevels')\n",
        "\n",
        "    # Aggregate review metrics\n",
        "    review_summary = reviews_df.groupby('ASIN').agg({\n",
        "        'CustomerID': 'count',\n",
        "        'Rating': 'mean',\n",
        "        'Votes': 'sum',\n",
        "        'Helpful': 'sum',\n",
        "        'Sentiment': 'mean'\n",
        "    }).rename(columns={\n",
        "        'CustomerID': 'NumReviews',\n",
        "        'Rating': 'AvgRating',\n",
        "        'Votes': 'TotalVotes',\n",
        "        'Helpful': 'TotalHelpful',\n",
        "        'Sentiment': 'AvgSentiment'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Join with products\n",
        "    products_enriched = products_df.merge(review_summary, on='ASIN', how='left')\n",
        "    products_enriched = products_enriched.fillna({\n",
        "        'NumReviews': 0, 'AvgRating': 0.0, 'TotalVotes': 0, 'TotalHelpful': 0, 'AvgSentiment': 0.0\n",
        "    })\n",
        "\n",
        "    # Save final cleaned data\n",
        "    products_enriched.to_csv('products_enriched.csv', index=False)\n",
        "    categories_expanded.to_csv('categories_expanded.csv', index=False)\n",
        "    reviews_df.to_csv('reviews_processed.csv', index=False)\n",
        "\n",
        "    return products_enriched, categories_expanded, reviews_df"
      ],
      "metadata": {
        "id": "Ikzj-sKiaDhz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute preprocessing\n",
        "print(\"Parsing Amazon metadata...\")\n",
        "parse_amazon_data()\n",
        "print(\"Converting and cleaning data...\")\n",
        "products_enriched, categories_expanded, reviews_processed = convert_data()\n",
        "print(\"Done. Cleaned data saved to products_enriched.csv, categories_expanded.csv, reviews_processed.csv, and edges.csv\")"
      ],
      "metadata": {
        "id": "3L5__vgfq0Cd",
        "outputId": "46e8f713-d5b6-432a-9985-2a62a21a8143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing Amazon metadata...\n",
            "Converting and cleaning data...\n",
            "Done. Cleaned data saved to products_enriched.csv, categories_expanded.csv, reviews_processed.csv, and edges.csv\n"
          ]
        }
      ]
    }
  ]
}