{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FredSadeghi/Amazon_CoPurchase_Network_Analysis/blob/main/BigDataAmazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K1oj8EP5ZgpE"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FredSadeghi/Amazon_CoPurchase_Network_Analysis.git"
      ],
      "metadata": {
        "id": "ZNa-1qgy9J5m",
        "outputId": "e364a102-2803-4500-a8b1-f55bba0ca1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Amazon_CoPurchase_Network_Analysis'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 7 (delta 1), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (7/7), 6.01 KiB | 3.01 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file\n",
        "input_file = 'amazon-meta.txt.gz'\n",
        "\n",
        "# Output files\n",
        "product_output = 'products.csv'\n",
        "edge_output = 'edges.csv'"
      ],
      "metadata": {
        "id": "s1GXTDjVZxOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_amazon_data():\n",
        "    with gzip.open(input_file, 'rt', encoding='latin-1') as f, \\\n",
        "         open(product_output, 'w', newline='', encoding='utf-8') as prod_out, \\\n",
        "         open(edge_output, 'w', newline='', encoding='utf-8') as edge_out:\n",
        "\n",
        "        product_writer = csv.writer(prod_out)\n",
        "        edge_writer = csv.writer(edge_out)\n",
        "\n",
        "        # Write headers\n",
        "        product_writer.writerow(['Id', 'ASIN', 'Title', 'Group', 'SalesRank'])\n",
        "        edge_writer.writerow(['SourceASIN', 'TargetASIN'])\n",
        "\n",
        "        current = {}\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            # New product entry\n",
        "            if line.startswith(\"Id:\"):\n",
        "                # Save previous product (if exists)\n",
        "                if current.get('ASIN') and current.get('Id'):\n",
        "                    product_writer.writerow([\n",
        "                        current.get('Id'),\n",
        "                        current.get('ASIN'),\n",
        "                        current.get('title', ''),\n",
        "                        current.get('group', ''),\n",
        "                        current.get('salesrank', '')\n",
        "                    ])\n",
        "                    for similar_asin in current.get('similar', []):\n",
        "                        edge_writer.writerow([current['ASIN'], similar_asin])\n",
        "                current = {'similar': []}\n",
        "                current['Id'] = line.split('Id:')[1].strip()\n",
        "\n",
        "            elif line.startswith(\"ASIN:\"):\n",
        "                current['ASIN'] = line.split(\"ASIN:\")[1].strip()\n",
        "\n",
        "            elif 'title:' in line:\n",
        "                match = re.search(r'title:\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current['title'] = match.group(1).strip()\n",
        "\n",
        "            elif 'group:' in line:\n",
        "                match = re.search(r'group:\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current['group'] = match.group(1).strip()\n",
        "\n",
        "            elif 'salesrank:' in line:\n",
        "                match = re.search(r'salesrank:\\s*(.*)', line)\n",
        "                if match:\n",
        "                    current['salesrank'] = match.group(1).strip()\n",
        "\n",
        "            elif line.startswith(\"similar:\"):\n",
        "                parts = line.split()\n",
        "                current['similar'] = parts[2:] if len(parts) > 2 else []\n",
        "\n",
        "        # Write last product\n",
        "        if current.get('ASIN') and current.get('Id'):\n",
        "            product_writer.writerow([\n",
        "                current.get('Id'),\n",
        "                current.get('ASIN'),\n",
        "                current.get('title', ''),\n",
        "                current.get('group', ''),\n",
        "                current.get('salesrank', '')\n",
        "            ])\n",
        "            for similar_asin in current.get('similar', []):\n",
        "                edge_writer.writerow([current['ASIN'], similar_asin])"
      ],
      "metadata": {
        "id": "4Y5iTTMiZ8-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Parsing Amazon metadata...\")\n",
        "parse_amazon_data()\n",
        "print(\"Done. Output saved to products.csv and edges.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "NM22QwiGaC2-",
        "outputId": "8a4464d3-e190-4775-bc59-2711452c1f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing Amazon metadata...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/colab/amazon-meta.txt.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b9c7145e74bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parsing Amazon metadata...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparse_amazon_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done. Output saved to products.csv and edges.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-108d8d6e0d0c>\u001b[0m in \u001b[0;36mparse_amazon_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_amazon_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m          \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprod_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0medge_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/colab/amazon-meta.txt.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O spark.tgz https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark.tgz && rm spark.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikzj-sKiaDhz",
        "outputId": "d2b2c7ac-2353-4533-c3bf-7752a6577691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-10 17:55:23--  https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400395283 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark.tgz’\n",
            "\n",
            "spark.tgz           100%[===================>] 381.85M  22.4MB/s    in 17s     \n",
            "\n",
            "2025-04-10 17:55:41 (21.9 MB/s) - ‘spark.tgz’ saved [400395283/400395283]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "3L5__vgfq0Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AmazonDataAnalysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "5val6Kvpq0w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products = spark.read.csv(\"products.csv\", header=True, inferSchema=True)\n",
        "edges = spark.read.csv(\"edges.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "Zn8nNQRiq7DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Calculate median and quartiles for SalesRank\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "products = products.withColumn(\"SalesRank\", products[\"SalesRank\"].cast(IntegerType()))\n",
        "quantiles = products.approxQuantile(\"SalesRank\", [0.25, 0.5, 0.75], 0.05)\n",
        "median = quantiles[1]\n",
        "q1 = quantiles[0]\n",
        "q3 = quantiles[2]\n",
        "print(f\"Median SalesRank: {median}\")\n",
        "print(f\"First Quartile SalesRank: {q1}\")\n",
        "print(f\"Third Quartile SalesRank: {q3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIg78vZ-q_x-",
        "outputId": "dad1401d-8acb-4579-bd9f-0d48875b4760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median SalesRank: 270086.0\n",
            "First Quartile SalesRank: 99602.0\n",
            "Third Quartile SalesRank: 610759.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import count, collect_list, explode, array_intersect, size, udf, col\n",
        "from pyspark.sql.types import IntegerType, FloatType\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "# Create a DataFrame of connected product pairs\n",
        "connected_pairs = edges.withColumnRenamed(\"SourceASIN\", \"ASIN1\").withColumnRenamed(\"TargetASIN\", \"ASIN2\")"
      ],
      "metadata": {
        "id": "L8n1BjqjrJIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "66b2c1e2-fca1-4da0-d7bc-af84b42d1430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fuzzywuzzy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2b1e2f5c8132>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_intersect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a DataFrame of connected product pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join with product features\n",
        "product_pairs_with_features = connected_pairs.join(products.alias(\"p1\"), connected_pairs.ASIN1 == col(\"p1.ASIN\")) \\\n",
        "    .join(products.alias(\"p2\"), connected_pairs.ASIN2 == col(\"p2.ASIN\")) \\\n",
        "    .select(\"ASIN1\", \"ASIN2\", \"p1.Group\", \"p2.Group\", \"p1.Title\", \"p2.Title\")"
      ],
      "metadata": {
        "id": "MU53DJV26706"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Similarity Calculation (Jaccard Similarity based on Group and Title Similarity)\n",
        "@udf(returnType=FloatType())\n",
        "def jaccard_similarity(group1, group2):\n",
        "    if group1 == group2:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "@udf(returnType=FloatType())\n",
        "def title_similarity(title1, title2):\n",
        "    return fuzz.ratio(title1, title2) / 100.0\n",
        "\n",
        "product_pairs_with_similarity = product_pairs_with_features.withColumn(\n",
        "    \"GroupSimilarity\",\n",
        "    jaccard_similarity(col(\"p1.Group\"), col(\"p2.Group\"))  # Use the column names \"Group\" and \"Group\"\n",
        ").withColumn(\n",
        "    \"TitleSimilarity\",\n",
        "    title_similarity(col(\"p1.Title\"), col(\"p2.Title\")) # Use the column names \"Title\" and \"Title\"\n",
        ")"
      ],
      "metadata": {
        "id": "0jO2S3T-9oU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Similarity Scores (Example: Average)\n",
        "product_pairs_with_combined_similarity = product_pairs_with_similarity.withColumn(\n",
        "    \"CombinedSimilarity\",\n",
        "    (col(\"GroupSimilarity\") + col(\"TitleSimilarity\")) / 2.0  # Example: Average of Group and Title similarity\n",
        ")"
      ],
      "metadata": {
        "id": "pZM4uSE-67pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for Similar Products (Example: Threshold of 0.8 - in this case only products in the same group)\n",
        "similar_products = product_pairs_with_combined_similarity.filter(\"CombinedSimilarity > 0.7\")\n",
        "\n",
        "similar_products.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d0tL26r7ehz",
        "outputId": "b7b7d922-e1d0-4175-a582-f700399cf19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-----+-----+--------------------+--------------------+---------------+---------------+------------------+\n",
            "|     ASIN1|     ASIN2|Group|Group|               Title|               Title|GroupSimilarity|TitleSimilarity|CombinedSimilarity|\n",
            "+----------+----------+-----+-----+--------------------+--------------------+---------------+---------------+------------------+\n",
            "|0002250535|0002154463| Book| Book|Italy Today The B...|Italy : The Beaut...|            1.0|           0.54|0.7699999809265137|\n",
            "|0002551543|0002154463| Book| Book|Provence : The Be...|Italy : The Beaut...|            1.0|           0.88|0.9399999976158142|\n",
            "|0002154129|0002154463| Book| Book|France the Beauti...|Italy : The Beaut...|            1.0|           0.57|0.7849999666213989|\n",
            "|000215949X|0002154463| Book| Book|Mexico : The Beau...|Italy : The Beaut...|            1.0|           0.89|0.9449999928474426|\n",
            "|0002550326|0002154463| Book| Book|Tuscany : The Bea...|Italy : The Beaut...|            1.0|           0.92|0.9600000381469727|\n",
            "|0002551152|0002154463| Book| Book|Asia: The Beautif...|Italy : The Beaut...|            1.0|           0.63|0.8149999976158142|\n",
            "|0002154463|0002250535| Book| Book|Italy : The Beaut...|Italy Today The B...|            1.0|           0.54|0.7699999809265137|\n",
            "|0002550326|0002250535| Book| Book|Tuscany : The Bea...|Italy Today The B...|            1.0|           0.49|0.7450000047683716|\n",
            "|0912365307|0002250985| Book| Book|Breakfast in Bed ...|Breakfast in Bed ...|            1.0|           0.53|0.7649999856948853|\n",
            "|1580080308|0002251337| Book| Book|Balsamico: A Bals...|The Balsamic Vine...|            1.0|           0.78|0.8899999856948853|\n",
            "|074321403X|0002251337| Book| Book|The Flavors of Ol...|The Balsamic Vine...|            1.0|           0.51|0.7549999952316284|\n",
            "|0002551543|0002251965| Book| Book|Provence : The Be...|South the Beautif...|            1.0|           0.56|0.7799999713897705|\n",
            "|0002553481|0002251965| Book| Book|Southwest : The B...|South the Beautif...|            1.0|           0.64|0.8199999928474426|\n",
            "|0002159317|0002251965| Book| Book|California the Be...|South the Beautif...|            1.0|           0.44|0.7200000286102295|\n",
            "|0002250357|0002251965| Book| Book|Texas the Beautif...|South the Beautif...|            1.0|           0.82|0.9099999666213989|\n",
            "|0002154129|0002550296| Book| Book|France the Beauti...|Thailand : The Be...|            1.0|           0.58|0.7899999618530273|\n",
            "|000215949X|0002550296| Book| Book|Mexico : The Beau...|Thailand : The Be...|            1.0|           0.89|0.9449999928474426|\n",
            "|0002551152|0002550296| Book| Book|Asia: The Beautif...|Thailand : The Be...|            1.0|           0.63|0.8149999976158142|\n",
            "|0688099173|0002550296| Book| Book|True Thai: The Mo...|Thailand : The Be...|            1.0|           0.46|0.7300000190734863|\n",
            "|0002551489|0002550857| Book| Book|The Best of Mexic...|The Best of Italy...|            1.0|           0.81|0.9049999713897705|\n",
            "+----------+----------+-----+-----+--------------------+--------------------+---------------+---------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Calculate entropy of product groups\n",
        "from pyspark.sql.functions import count, log2\n",
        "\n",
        "group_counts = products.groupBy(\"Group\").agg(count(\"*\").alias(\"count\"))\n",
        "total_count = products.count()\n",
        "entropy = -group_counts.selectExpr(\n",
        "    \"SUM(count / {} * log2(count / {})) as entropy\".format(total_count, total_count)\n",
        ").first().entropy\n",
        "\n",
        "print(f\"Entropy of product groups: {entropy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXkFPbk0rx2q",
        "outputId": "f41a58ee-295e-4d24-aadc-4bd143af66b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropy of product groups: 1.2607732770291709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jci36gjDr3ur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}